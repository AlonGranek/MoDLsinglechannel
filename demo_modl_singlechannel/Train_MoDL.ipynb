{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os, sys\n",
    "import logging\n",
    "import random\n",
    "import h5py\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sigpy.plot as pl\n",
    "import torch\n",
    "import sigpy as sp\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "# import custom libraries\n",
    "from utils import transforms as T\n",
    "from utils import subsample as ss\n",
    "from utils import complex_utils as cplx\n",
    "from utils.resnet2p1d import generate_model\n",
    "from utils.flare_utils import roll\n",
    "# import custom classes\n",
    "from utils.datasets import SliceData\n",
    "from subsample_fastmri import MaskFunc\n",
    "from MoDL_single import UnrolledModel\n",
    "import argparse\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "%load_ext autoreload\n",
    "%autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer for training unrolled reconstruction models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_func, args, use_seed=False):\n",
    "        self.mask_func = mask_func\n",
    "        self.use_seed = use_seed\n",
    "        self.rng = np.random.RandomState()\n",
    "\n",
    "    # def __call__(self, kspace, target, slice):\n",
    "    #     im_lowres = abs(sp.ifft(sp.resize(sp.resize(kspace,(640,24)),(640,372))))\n",
    "    #     magnitude_vals = im_lowres.reshape(-1)\n",
    "    #     k = int(round(0.05 * magnitude_vals.shape[0]))\n",
    "    #     scale = magnitude_vals[magnitude_vals.argsort()[::-1][k]]\n",
    "    #     kspace = kspace/scale\n",
    "    #     target = target/scale\n",
    "    #     # Convert everything from numpy arrays to tensors\n",
    "    #     kspace_torch = cplx.to_tensor(kspace).float()   \n",
    "    #     target_torch = cplx.to_tensor(target).float()   \n",
    "    #     mask_slice = np.ones((640,372))\n",
    "    #     mk1 = self.mask_func((1,1,372,2))[0,0,:,0]\n",
    "    #     knee_masks = mask_slice*mk1\n",
    "    #     mask_torch = torch.tensor(knee_masks[...,None]).float()\n",
    "    #     mask2 = sp.mri.poisson((640,372), 4, calib=(70, 56), dtype=float, crop_corner=True, return_density=False, seed=0, max_attempts=6, tol=0.1)\n",
    "    #     mask_torch = torch.stack([torch.tensor(mask2).float(),torch.tensor(mask2).float()],dim=2)\n",
    "    #     kspace_torch = kspace_torch*mask_torch\n",
    "    # \n",
    "    #     return kspace_torch,target_torch,mask_torch\n",
    "    \n",
    "    def normalization(self, image: np.ndarray):\n",
    "        norm_percentile = 95\n",
    "        vals = image.reshape(-1)\n",
    "        n_taken = int(round((1 - norm_percentile * 1e-2) * vals.shape[0]))\n",
    "        scale = vals[vals.argsort()[::-1][n_taken]]\n",
    "        return scale\n",
    "    \n",
    "    def __call__(self, kspace, target):\n",
    "        \"\"\"\n",
    "        The forward model.\n",
    "        \n",
    "        :param kspace: \n",
    "        :param target: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        # Normalize\n",
    "        scale = self.normalization(target)\n",
    "        kspace /= scale\n",
    "        target /= scale\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        kspace_torch = cplx.to_tensor(kspace).float()   \n",
    "        target_torch = cplx.to_tensor(target).float() \n",
    "        \n",
    "        # k-space masking\n",
    "        mask = sp.mri.poisson(\n",
    "            img_shape=(372, 372),\n",
    "            accel=6, #4,\n",
    "            calib=(56, 56),\n",
    "            dtype=float, crop_corner=True, return_density=False, seed=0, max_attempts=6, tol=0.1\n",
    "        )\n",
    "        mask_torch = torch.stack([torch.tensor(mask).float(),torch.tensor(mask).float()],dim=2)\n",
    "        kspace_masked = kspace_torch * mask_torch\n",
    "        \n",
    "        return kspace_masked, target_torch, mask_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(args):\n",
    "    # Generate k-t undersampling masks\n",
    "    train_mask = MaskFunc([0.08],[4])\n",
    "    train_data = SliceData(\n",
    "        root=str(args.data_path),\n",
    "        transform=DataTransform(train_mask, args),\n",
    "        sample_rate=1\n",
    "    )\n",
    "    return train_data\n",
    "def create_data_loaders(args):\n",
    "    train_data = create_datasets(args)\n",
    "    print(len(train_data))\n",
    "#     print(train_data[0])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader\n",
    "def build_optim(args, params):\n",
    "    optimizer = torch.optim.Adam(params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "params = Namespace()\n",
    "params.data_path = '/mnt/c/Users/along/brain_multicoil_train_batch_0/multicoil_train' #\"../../single_channel_data/train/\"\n",
    "params.batch_size = 2 #4\n",
    "params.num_grad_steps = 3 #4\n",
    "params.num_cg_steps = 8\n",
    "params.share_weights = True\n",
    "params.modl_lamda = 0.05\n",
    "params.lr = 0.0001\n",
    "params.weight_decay = 0\n",
    "params.lr_step_size = 500\n",
    "params.lr_gamma = 0.5\n",
    "params.epoch = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_data_loaders(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_MoDL = UnrolledModel(params).to(device)\n",
    "optimizer = build_optim(params, single_MoDL.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, params.lr_step_size, params.lr_gamma)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for epoch in range(params.epoch):\n",
    "    print(f'Epoch {epoch}')\n",
    "    single_MoDL.train()\n",
    "    avg_loss = 0.\n",
    "\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        print(f'{iter=}...')\n",
    "        \n",
    "        try:\n",
    "            # if True:\n",
    "            input,target,mask = data\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            mask = mask.to(device)\n",
    "            \n",
    "            # fig, ax = plt.subplots(1, 2)\n",
    "            # ax[0].imshow(10 * np.log10(np.maximum(abs(input)[0, ..., 0], 1e-8)), cmap='inferno')\n",
    "            # ax[1].imshow(target[0, ..., 0], cmap='inferno')\n",
    "            # plt.show()\n",
    "            # raise ValueError\n",
    "        except:\n",
    "            continue\n",
    "        print(f'\\tDone data prep. {input.shape=} {target.shape=}')\n",
    "        im_out = single_MoDL(input.float(),mask=mask)\n",
    "        print(f'\\tGenerated image. {im_out.shape=}')\n",
    "        loss = criterion(im_out,target)\n",
    "        print(f'\\tFound loss')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'\\tDone backprop')\n",
    "        avg_loss = 0.99 * avg_loss + 0.01 * loss.item() if iter > 0 else loss.item()\n",
    "        print(f'\\tInstant loss: {loss.item()}. \\t\\tAvg loss: {avg_loss}')\n",
    "        if iter % 20 == 0:\n",
    "            logging.info(\n",
    "                f'Epoch = [{epoch:3d}/{params.epoch:3d}] '\n",
    "                f'Iter = [{iter:4d}/{len(train_loader):4d}] '\n",
    "                f'Loss = {loss.item():.4g} Avg Loss = {avg_loss:.4g}'\n",
    "            )\n",
    "    #Saving the model\n",
    "    exp_dir = '/home/alon_granek/PythonProjects/NPPC/alon/checkpoints2' #\"L2_checkpoints_poisson_x4/\"\n",
    "    Path(exp_dir).mkdir(exist_ok=True)\n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'params': params,\n",
    "            'model': single_MoDL.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'exp_dir': exp_dir\n",
    "        },\n",
    "        f=os.path.join(exp_dir, 'model_%d.pt'%(epoch))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample = 0\n",
    "\n",
    "recon_image = cplx.abs(im_out.detach())\n",
    "gt_image = cplx.abs(target.detach())\n",
    "\n",
    "from alon.fastmri_preprocess import ifftc, fftc\n",
    "in_kspace = input.detach()\n",
    "in_image = abs(ifftc(torch.tensor(fftc(gt_image)) * mask[..., 0]))  #abs(ifftc(in_kspace[..., 0]) + 1j * ifftc(in_kspace[..., 1]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].set_title('Target')\n",
    "ax[0].imshow(gt_image[sample], cmap='Greys_r', vmin=0, vmax=1.2)\n",
    "ax[1].set_title('4x accelerated zero-filled')\n",
    "ax[1].imshow(in_image[sample], cmap='Greys_r', vmin=0, vmax=1.2)\n",
    "ax[2].set_title('Reconstructed')\n",
    "ax[2].imshow(recon_image[sample], cmap='Greys_r', vmin=0, vmax=1.2)\n",
    "fig.set_size_inches(15, 7)\n",
    "plt.tight_layout()\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plt.savefig('/home/alon_granek/PythonProjects/NPPC/run.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Connecting MoDL to NPPC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
