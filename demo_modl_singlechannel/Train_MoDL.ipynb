{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os, sys\n",
    "import logging\n",
    "import random\n",
    "import h5py\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sigpy.plot as pl\n",
    "import torch\n",
    "import sigpy as sp\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "# import custom libraries\n",
    "from utils import transforms as T\n",
    "from utils import subsample as ss\n",
    "from utils import complex_utils as cplx\n",
    "from utils.resnet2p1d import generate_model\n",
    "from utils.flare_utils import roll\n",
    "# import custom classes\n",
    "from utils.datasets import SliceData\n",
    "from subsample_fastmri import MaskFunc\n",
    "from MoDL_single import UnrolledModel\n",
    "import argparse\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "%load_ext autoreload\n",
    "%autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer for training unrolled reconstruction models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_func, args, use_seed=False):\n",
    "        self.mask_func = mask_func\n",
    "        self.use_seed = use_seed\n",
    "        self.rng = np.random.RandomState()\n",
    "\n",
    "    def __call__(self, kspace, target, slice):\n",
    "        im_lowres = abs(sp.ifft(sp.resize(sp.resize(kspace,(640,24)),(640,372))))\n",
    "        magnitude_vals = im_lowres.reshape(-1)\n",
    "        k = int(round(0.05 * magnitude_vals.shape[0]))\n",
    "        scale = magnitude_vals[magnitude_vals.argsort()[::-1][k]]\n",
    "        kspace = kspace/scale\n",
    "        target = target/scale\n",
    "        # Convert everything from numpy arrays to tensors\n",
    "        kspace_torch = cplx.to_tensor(kspace).float()   \n",
    "        target_torch = cplx.to_tensor(target).float()   \n",
    "        mask_slice = np.ones((640,372))\n",
    "        mk1 = self.mask_func((1,1,372,2))[0,0,:,0]\n",
    "        knee_masks = mask_slice*mk1\n",
    "        mask_torch = torch.tensor(knee_masks[...,None]).float()\n",
    "        mask2 = sp.mri.poisson((640,372), 4, calib=(70, 56), dtype=float, crop_corner=True, return_density=False, seed=0, max_attempts=6, tol=0.1)\n",
    "        mask_torch = torch.stack([torch.tensor(mask2).float(),torch.tensor(mask2).float()],dim=2)\n",
    "        kspace_torch = kspace_torch*mask_torch\n",
    "\n",
    "        return kspace_torch,target_torch,mask_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(args):\n",
    "    # Generate k-t undersampling masks\n",
    "    train_mask = MaskFunc([0.08],[4])\n",
    "    train_data = SliceData(\n",
    "        root=str(args.data_path),\n",
    "        transform=DataTransform(train_mask, args),\n",
    "        sample_rate=1\n",
    "    )\n",
    "    return train_data\n",
    "def create_data_loaders(args):\n",
    "    train_data = create_datasets(args)\n",
    "#     print(train_data[0])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader\n",
    "def build_optim(args, params):\n",
    "    optimizer = torch.optim.Adam(params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "params = Namespace()\n",
    "params.data_path = \"../../single_channel_data/train/\"\n",
    "params.batch_size = 4\n",
    "params.num_grad_steps = 4\n",
    "params.num_cg_steps = 8\n",
    "params.share_weights = True\n",
    "params.modl_lamda = 0.05\n",
    "params.lr = 0.0001\n",
    "params.weight_decay = 0\n",
    "params.lr_step_size = 500\n",
    "params.lr_gamma = 0.5\n",
    "params.epoch = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_data_loaders(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights\n"
     ]
    }
   ],
   "source": [
    "single_MoDL = UnrolledModel(params).to(device)\n",
    "optimizer = build_optim(params, single_MoDL.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, params.lr_step_size, params.lr_gamma)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  0/ 21] Iter = [   0/  63] Loss = 0.02874 Avg Loss = 0.02874\n",
      "INFO:root:Epoch = [  0/ 21] Iter = [  20/  63] Loss = 0.02513 Avg Loss = 0.02753\n",
      "INFO:root:Epoch = [  0/ 21] Iter = [  40/  63] Loss = 0.0326 Avg Loss = 0.02684\n",
      "INFO:root:Epoch = [  0/ 21] Iter = [  60/  63] Loss = 0.02986 Avg Loss = 0.0263\n",
      "INFO:root:Epoch = [  1/ 21] Iter = [   0/  63] Loss = 0.02364 Avg Loss = 0.02364\n",
      "INFO:root:Epoch = [  1/ 21] Iter = [  20/  63] Loss = 0.03104 Avg Loss = 0.02316\n",
      "INFO:root:Epoch = [  1/ 21] Iter = [  40/  63] Loss = 0.01476 Avg Loss = 0.02278\n",
      "INFO:root:Epoch = [  1/ 21] Iter = [  60/  63] Loss = 0.01066 Avg Loss = 0.02307\n",
      "INFO:root:Epoch = [  2/ 21] Iter = [   0/  63] Loss = 0.01961 Avg Loss = 0.01961\n",
      "INFO:root:Epoch = [  2/ 21] Iter = [  20/  63] Loss = 0.01176 Avg Loss = 0.01969\n",
      "INFO:root:Epoch = [  2/ 21] Iter = [  40/  63] Loss = 0.02 Avg Loss = 0.02016\n",
      "INFO:root:Epoch = [  2/ 21] Iter = [  60/  63] Loss = 0.0354 Avg Loss = 0.02102\n",
      "INFO:root:Epoch = [  3/ 21] Iter = [   0/  63] Loss = 0.02611 Avg Loss = 0.02611\n",
      "INFO:root:Epoch = [  3/ 21] Iter = [  20/  63] Loss = 0.01281 Avg Loss = 0.02589\n",
      "INFO:root:Epoch = [  3/ 21] Iter = [  40/  63] Loss = 0.01311 Avg Loss = 0.02512\n",
      "INFO:root:Epoch = [  3/ 21] Iter = [  60/  63] Loss = 0.009641 Avg Loss = 0.02406\n",
      "INFO:root:Epoch = [  4/ 21] Iter = [   0/  63] Loss = 0.03664 Avg Loss = 0.03664\n",
      "INFO:root:Epoch = [  4/ 21] Iter = [  20/  63] Loss = 0.01806 Avg Loss = 0.03351\n",
      "INFO:root:Epoch = [  4/ 21] Iter = [  40/  63] Loss = 0.02361 Avg Loss = 0.03143\n",
      "INFO:root:Epoch = [  4/ 21] Iter = [  60/  63] Loss = 0.03245 Avg Loss = 0.02995\n",
      "INFO:root:Epoch = [  5/ 21] Iter = [   0/  63] Loss = 0.01668 Avg Loss = 0.01668\n",
      "INFO:root:Epoch = [  5/ 21] Iter = [  20/  63] Loss = 0.03355 Avg Loss = 0.01762\n",
      "INFO:root:Epoch = [  5/ 21] Iter = [  40/  63] Loss = 0.04188 Avg Loss = 0.01863\n",
      "INFO:root:Epoch = [  5/ 21] Iter = [  60/  63] Loss = 0.02092 Avg Loss = 0.01918\n",
      "INFO:root:Epoch = [  6/ 21] Iter = [   0/  63] Loss = 0.0187 Avg Loss = 0.0187\n",
      "INFO:root:Epoch = [  6/ 21] Iter = [  20/  63] Loss = 0.01906 Avg Loss = 0.01937\n",
      "INFO:root:Epoch = [  6/ 21] Iter = [  40/  63] Loss = 0.01877 Avg Loss = 0.0198\n",
      "INFO:root:Epoch = [  6/ 21] Iter = [  60/  63] Loss = 0.0399 Avg Loss = 0.0204\n",
      "INFO:root:Epoch = [  7/ 21] Iter = [   0/  63] Loss = 0.02018 Avg Loss = 0.02018\n",
      "INFO:root:Epoch = [  7/ 21] Iter = [  20/  63] Loss = 0.03268 Avg Loss = 0.02078\n",
      "INFO:root:Epoch = [  7/ 21] Iter = [  40/  63] Loss = 0.0181 Avg Loss = 0.02052\n",
      "INFO:root:Epoch = [  7/ 21] Iter = [  60/  63] Loss = 0.02452 Avg Loss = 0.02098\n",
      "INFO:root:Epoch = [  8/ 21] Iter = [   0/  63] Loss = 0.02959 Avg Loss = 0.02959\n",
      "INFO:root:Epoch = [  8/ 21] Iter = [  20/  63] Loss = 0.01583 Avg Loss = 0.02794\n",
      "INFO:root:Epoch = [  8/ 21] Iter = [  40/  63] Loss = 0.01384 Avg Loss = 0.02659\n",
      "INFO:root:Epoch = [  8/ 21] Iter = [  60/  63] Loss = 0.03629 Avg Loss = 0.02601\n",
      "INFO:root:Epoch = [  9/ 21] Iter = [   0/  63] Loss = 0.03205 Avg Loss = 0.03205\n",
      "INFO:root:Epoch = [  9/ 21] Iter = [  20/  63] Loss = 0.01886 Avg Loss = 0.02982\n",
      "INFO:root:Epoch = [  9/ 21] Iter = [  40/  63] Loss = 0.02304 Avg Loss = 0.02855\n",
      "INFO:root:Epoch = [  9/ 21] Iter = [  60/  63] Loss = 0.01932 Avg Loss = 0.02737\n",
      "INFO:root:Epoch = [ 10/ 21] Iter = [   0/  63] Loss = 0.0299 Avg Loss = 0.0299\n",
      "INFO:root:Epoch = [ 10/ 21] Iter = [  20/  63] Loss = 0.02004 Avg Loss = 0.02821\n",
      "INFO:root:Epoch = [ 10/ 21] Iter = [  40/  63] Loss = 0.02441 Avg Loss = 0.02749\n",
      "INFO:root:Epoch = [ 10/ 21] Iter = [  60/  63] Loss = 0.01127 Avg Loss = 0.02624\n",
      "INFO:root:Epoch = [ 11/ 21] Iter = [   0/  63] Loss = 0.03001 Avg Loss = 0.03001\n",
      "INFO:root:Epoch = [ 11/ 21] Iter = [  20/  63] Loss = 0.006405 Avg Loss = 0.02869\n",
      "INFO:root:Epoch = [ 11/ 21] Iter = [  40/  63] Loss = 0.01394 Avg Loss = 0.02738\n",
      "INFO:root:Epoch = [ 11/ 21] Iter = [  60/  63] Loss = 0.01656 Avg Loss = 0.02609\n",
      "INFO:root:Epoch = [ 12/ 21] Iter = [   0/  63] Loss = 0.01216 Avg Loss = 0.01216\n",
      "INFO:root:Epoch = [ 12/ 21] Iter = [  20/  63] Loss = 0.04329 Avg Loss = 0.01425\n",
      "INFO:root:Epoch = [ 12/ 21] Iter = [  40/  63] Loss = 0.02664 Avg Loss = 0.01547\n",
      "INFO:root:Epoch = [ 12/ 21] Iter = [  60/  63] Loss = 0.03234 Avg Loss = 0.01666\n",
      "INFO:root:Epoch = [ 13/ 21] Iter = [   0/  63] Loss = 0.0314 Avg Loss = 0.0314\n",
      "INFO:root:Epoch = [ 13/ 21] Iter = [  20/  63] Loss = 0.01897 Avg Loss = 0.02961\n",
      "INFO:root:Epoch = [ 13/ 21] Iter = [  40/  63] Loss = 0.008336 Avg Loss = 0.02813\n",
      "INFO:root:Epoch = [ 13/ 21] Iter = [  60/  63] Loss = 0.02888 Avg Loss = 0.02703\n",
      "INFO:root:Epoch = [ 14/ 21] Iter = [   0/  63] Loss = 0.02227 Avg Loss = 0.02227\n",
      "INFO:root:Epoch = [ 14/ 21] Iter = [  20/  63] Loss = 0.01672 Avg Loss = 0.02259\n",
      "INFO:root:Epoch = [ 14/ 21] Iter = [  40/  63] Loss = 0.02342 Avg Loss = 0.02219\n",
      "INFO:root:Epoch = [ 14/ 21] Iter = [  60/  63] Loss = 0.03337 Avg Loss = 0.02194\n",
      "INFO:root:Epoch = [ 15/ 21] Iter = [   0/  63] Loss = 0.01194 Avg Loss = 0.01194\n",
      "INFO:root:Epoch = [ 15/ 21] Iter = [  20/  63] Loss = 0.01823 Avg Loss = 0.01369\n",
      "INFO:root:Epoch = [ 15/ 21] Iter = [  40/  63] Loss = 0.02195 Avg Loss = 0.01521\n",
      "INFO:root:Epoch = [ 15/ 21] Iter = [  60/  63] Loss = 0.01102 Avg Loss = 0.01661\n",
      "INFO:root:Epoch = [ 16/ 21] Iter = [   0/  63] Loss = 0.01092 Avg Loss = 0.01092\n",
      "INFO:root:Epoch = [ 16/ 21] Iter = [  20/  63] Loss = 0.03535 Avg Loss = 0.01253\n",
      "INFO:root:Epoch = [ 16/ 21] Iter = [  40/  63] Loss = 0.02716 Avg Loss = 0.01459\n",
      "INFO:root:Epoch = [ 16/ 21] Iter = [  60/  63] Loss = 0.02787 Avg Loss = 0.01592\n",
      "INFO:root:Epoch = [ 17/ 21] Iter = [   0/  63] Loss = 0.02226 Avg Loss = 0.02226\n",
      "INFO:root:Epoch = [ 17/ 21] Iter = [  20/  63] Loss = 0.01711 Avg Loss = 0.0223\n",
      "INFO:root:Epoch = [ 17/ 21] Iter = [  40/  63] Loss = 0.01419 Avg Loss = 0.02197\n",
      "INFO:root:Epoch = [ 17/ 21] Iter = [  60/  63] Loss = 0.006657 Avg Loss = 0.02189\n",
      "INFO:root:Epoch = [ 18/ 21] Iter = [   0/  63] Loss = 0.02529 Avg Loss = 0.02529\n",
      "INFO:root:Epoch = [ 18/ 21] Iter = [  20/  63] Loss = 0.02186 Avg Loss = 0.02465\n",
      "INFO:root:Epoch = [ 18/ 21] Iter = [  40/  63] Loss = 0.005047 Avg Loss = 0.02354\n",
      "INFO:root:Epoch = [ 18/ 21] Iter = [  60/  63] Loss = 0.02578 Avg Loss = 0.02353\n",
      "INFO:root:Epoch = [ 19/ 21] Iter = [   0/  63] Loss = 0.01692 Avg Loss = 0.01692\n",
      "INFO:root:Epoch = [ 19/ 21] Iter = [  20/  63] Loss = 0.01652 Avg Loss = 0.01785\n",
      "INFO:root:Epoch = [ 19/ 21] Iter = [  40/  63] Loss = 0.01996 Avg Loss = 0.019\n",
      "INFO:root:Epoch = [ 19/ 21] Iter = [  60/  63] Loss = 0.02686 Avg Loss = 0.01904\n",
      "INFO:root:Epoch = [ 20/ 21] Iter = [   0/  63] Loss = 0.01912 Avg Loss = 0.01912\n",
      "INFO:root:Epoch = [ 20/ 21] Iter = [  20/  63] Loss = 0.03695 Avg Loss = 0.01971\n",
      "INFO:root:Epoch = [ 20/ 21] Iter = [  40/  63] Loss = 0.02611 Avg Loss = 0.02019\n",
      "INFO:root:Epoch = [ 20/ 21] Iter = [  60/  63] Loss = 0.02637 Avg Loss = 0.02022\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for epoch in range(params.epoch):\n",
    "    single_MoDL.train()\n",
    "    avg_loss = 0.\n",
    "\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        input,target,mask = data\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        mask = mask.to(device)\n",
    "        im_out = single_MoDL(input.float(),mask=mask)\n",
    "        loss = criterion(im_out,target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss = 0.99 * avg_loss + 0.01 * loss.item() if iter > 0 else loss.item()\n",
    "        if iter % 20 == 0:\n",
    "            logging.info(\n",
    "                f'Epoch = [{epoch:3d}/{params.epoch:3d}] '\n",
    "                f'Iter = [{iter:4d}/{len(train_loader):4d}] '\n",
    "                f'Loss = {loss.item():.4g} Avg Loss = {avg_loss:.4g}'\n",
    "            )\n",
    "    #Saving the model\n",
    "    exp_dir = \"L2_checkpoints_poisson_x4/\"\n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'params': params,\n",
    "            'model': single_MoDL.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'exp_dir': exp_dir\n",
    "        },\n",
    "        f=os.path.join(exp_dir, 'model_%d.pt'%(epoch))\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
