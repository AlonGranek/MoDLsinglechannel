{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import os, sys\n",
    "import logging\n",
    "import random\n",
    "import h5py\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sigpy.plot as pl\n",
    "import torch\n",
    "import sigpy as sp\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "# import custom libraries\n",
    "from utils import transforms as T\n",
    "from utils import subsample as ss\n",
    "from utils import complex_utils as cplx\n",
    "from utils.resnet2p1d import generate_model\n",
    "from utils.flare_utils import roll\n",
    "from utils import data_ut as dut\n",
    "# import custom classes\n",
    "from utils.datasets import SliceData\n",
    "from subsample_fastmri import MaskFunc\n",
    "from MoDL_single import UnrolledModel\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "from models.SAmodel import MyNetwork\n",
    "from models.Unrolled import Unrolled\n",
    "from models.UnrolledRef import UnrolledRef\n",
    "from models.UnrolledTransformer import UnrolledTrans\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "%load_ext autoreload\n",
    "%autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tal/docker/MoDLsinglechannel/modl_singlechannel_reference\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tal/docker/dockvenv/bin/python3\n"
     ]
    }
   ],
   "source": [
    "!which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = \"./L2_checkpoints_poisson_x4_SAunrolledOF/model_10.pt\"\n",
    "checkpoint = torch.load(checkpoint_file,map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = checkpoint[\"params\"]\n",
    "#single_MoDL = UnrolledModel(params).to(device)\n",
    "#single_MoDL = MyNetwork(2,2).to(device)\n",
    "single_MoDL = Unrolled(params).to(device)\n",
    "#single_MoDL = UnrolledRef(params).to(device)\n",
    "#single_MoDL = UnrolledTrans(params).to(device)\n",
    "single_MoDL.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer for training unrolled reconstruction models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_func, args, use_seed=False):\n",
    "        self.mask_func = mask_func\n",
    "        self.use_seed = use_seed\n",
    "        self.rng = np.random.RandomState()\n",
    "\n",
    "    def __call__(self, kspace, target, reference, reference_kspace,slice):\n",
    "       \n",
    "        im_lowres = abs(sp.ifft(sp.resize(sp.resize(kspace,(172,24)),(172,108))))\n",
    "        magnitude_vals = im_lowres.reshape(-1)\n",
    "        k = int(round(0.05 * magnitude_vals.shape[0]))\n",
    "        scale = magnitude_vals[magnitude_vals.argsort()[::-1][k]]\n",
    "        kspace = kspace/scale\n",
    "\n",
    "        # Convert everything from numpy arrays to tensors\n",
    "        kspace_torch = cplx.to_tensor(kspace).float()   \n",
    "        target_torch = cplx.to_tensor(target).float() / scale\n",
    "        \n",
    "        # Use poisson mask instead\n",
    "        mask2 = sp.mri.poisson((172,108), 2, calib=(18, 14), dtype=float, crop_corner=False, return_density=True, seed=0, max_attempts=6, tol=0.01)\n",
    "        mask_torch = torch.stack([torch.tensor(mask2).float(),torch.tensor(mask2).float()],dim=2)\n",
    "    \n",
    "        #kspace_torch = T.kspace_cut(mask_torch,0.5)\n",
    "        kspace_torch = T.awgn_torch(kspace_torch,15,L=1)\n",
    "        kspace_torch = kspace_torch*mask_torch\n",
    "\n",
    "    \n",
    "        ### Reference addition ###\n",
    "        im_lowres_ref = abs(sp.ifft(sp.resize(sp.resize(reference_kspace,(172,24)),(172,108))))\n",
    "        magnitude_vals_ref = im_lowres_ref.reshape(-1)\n",
    "        k_ref = int(round(0.05 * magnitude_vals_ref.shape[0]))\n",
    "        scale_ref = magnitude_vals_ref[magnitude_vals_ref.argsort()[::-1][k_ref]]\n",
    "        reference_torch = cplx.to_tensor(reference).float()/ scale_ref\n",
    "        # Resolution degrading\n",
    "       \n",
    "        return kspace_torch, target_torch,mask_torch, reference_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(args):\n",
    "    # Generate k-t undersampling masks\n",
    "    train_mask = MaskFunc([0.08],[4])\n",
    "    train_data = SliceData(\n",
    "        root=str(args.data_path),\n",
    "        transform=DataTransform(train_mask, args),\n",
    "        sample_rate=1\n",
    "    )\n",
    "    return train_data\n",
    "def create_data_loaders(args):\n",
    "    train_data = create_datasets(args)\n",
    "#     print(train_data[0])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader\n",
    "def build_optim(args, params):\n",
    "    optimizer = torch.optim.Adam(params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights\n",
      "Average MSE input: 0.006740964591199441\n",
      "Average MSE output: 0.004576812963932753\n",
      "Average PSNR input: 38.877258084369274\n",
      "Average PSNR output: 55.392005920410156\n",
      "Average SSIM input: 0.9041\n",
      "Average SSIM output: 0.9913\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr, normalized_root_mse as nrmse\n",
    "from skimage import img_as_float\n",
    "from types import SimpleNamespace as Namespace\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "params = Namespace()\n",
    "params.data_path = \"./test_data/\"\n",
    "params.batch_size = 1\n",
    "params.num_grad_steps = 4\n",
    "params.num_cg_steps = 8\n",
    "params.share_weights = True\n",
    "params.modl_lamda = 0.05\n",
    "params.lr = 0.0001\n",
    "params.weight_decay = 0\n",
    "params.lr_step_size = 10\n",
    "params.lr_gamma = 0.5\n",
    "params.epoch = 21\n",
    "params.reference_mode = 0\n",
    "params.reference_lambda = 0.1\n",
    "\n",
    "# Load test data\n",
    "test_loader = create_data_loaders(params)\n",
    "checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "single_MoDL = Unrolled(params).to(device)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "mse_in_list, mse_out_list = [], []\n",
    "psnr_in_list, psnr_out_list = [], []\n",
    "ssim_in_list, ssim_out_list = [], []\n",
    "\n",
    "single_MoDL.eval()  # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for data in test_loader:\n",
    "        input, target, mask, reference = data\n",
    "        input = input.to(device)\n",
    "        reference = reference.to(device)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        output = single_MoDL(input.float(),reference)\n",
    "        \n",
    "        # Convert tensors to numpy arrays\n",
    "        cplx_image_target = np.abs(cplx.to_numpy(T.fft2(target.cpu()))).squeeze(0)\n",
    "        cplx_image_in = np.abs(cplx.to_numpy(input.cpu()).squeeze(0))\n",
    "        cplx_image_out = np.abs(cplx.to_numpy(T.fft2(output.cpu())).squeeze(0))\n",
    "\n",
    "        img_target = img_as_float(np.abs(cplx_image_target))/np.max(np.abs(cplx_image_target))\n",
    "        img_in = img_as_float(np.abs(cplx_image_in)/np.max(cplx_image_in))/np.max(np.abs(cplx_image_in))\n",
    "        img_out = img_as_float(np.abs(cplx_image_out))/np.max(np.abs(cplx_image_out))\n",
    "\n",
    "        # Calculate metrics\n",
    "        # Calculate SSIM\n",
    "        data_range = img_target.max() - img_target.min()\n",
    "        ssim_in, _ = ssim(img_target, img_in, data_range=data_range, full=True)\n",
    "        ssim_out, _ = ssim(img_target, img_out, data_range=data_range, full=True)\n",
    "        \n",
    "        # Calculate PSNR\n",
    "        psnr_in = T.PSNR(cplx.to_tensor(img_target).unsqueeze(0),cplx.to_tensor( img_in).unsqueeze(0))\n",
    "        psnr_out = T.PSNR(cplx.to_tensor(img_target).unsqueeze(0), cplx.to_tensor(img_out).unsqueeze(0))\n",
    "\n",
    "        # Calculate MSE\n",
    "        mse_in = np.mean(np.abs(cplx_image_in-cplx_image_target)**2)\n",
    "        mse_out = np.mean(np.abs(cplx_image_out-cplx_image_target)**2)\n",
    "\n",
    "        # Append metrics to lists\n",
    "        mse_in_list.append(mse_in)\n",
    "        mse_out_list.append(mse_out)\n",
    "        psnr_in_list.append(psnr_in.numpy())\n",
    "        psnr_out_list.append(psnr_out.numpy())\n",
    "        ssim_in_list.append(ssim_in)\n",
    "        ssim_out_list.append(ssim_out)\n",
    "\n",
    "\n",
    "# Calculate and print average metrics\n",
    "print(f'Average MSE input: {np.mean(mse_in_list)}')\n",
    "print(f'Average MSE output: {np.mean(mse_out_list)}')\n",
    "print(f'Average PSNR input: {np.mean(psnr_in_list)}')\n",
    "print(f'Average PSNR output: {np.mean(psnr_out_list)}')\n",
    "print(f'Average SSIM input: {np.mean(ssim_in_list):.4f}')\n",
    "print(f'Average SSIM output: {np.mean(ssim_out_list):.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
